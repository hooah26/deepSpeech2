{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12745547",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "from GetSpeech import get_speech\n",
    "from tools import revise\n",
    "from kospeech.vocabs.ksponspeech import KsponSpeechVocabulary\n",
    "from kospeech.models import DeepSpeech2\n",
    "\n",
    "def parser(signal, audio_extension: str = 'pcm') -> Tensor:\n",
    "\n",
    "    feature = torchaudio.compliance.kaldi.fbank(\n",
    "        waveform=Tensor(signal).unsqueeze(0),\n",
    "        num_mel_bins=80,\n",
    "        frame_length=20,\n",
    "        frame_shift=10,\n",
    "        window_type='hamming'\n",
    "    ).transpose(0, 1).numpy()\n",
    "\n",
    "    feature -= feature.mean()\n",
    "    feature /= np.std(feature)\n",
    "\n",
    "    return torch.FloatTensor(feature).transpose(0, 1)\n",
    "\n",
    "model_path = \"./model_ds2.pt\"\n",
    "device = \"cpu\"\n",
    "\n",
    "# Get Speech data\n",
    "audiodata = get_speech()\n",
    "wav_data = librosa.util.buf_to_float(audiodata)\n",
    "\n",
    "# Transform to input\n",
    "feature = parser(wav_data)\n",
    "input_length = torch.LongTensor([len(feature)])\n",
    "vocab = KsponSpeechVocabulary('./aihub_character_vocabs.csv')\n",
    "\n",
    "# Load Kospeech Models\n",
    "model = torch.load(model_path, map_location=lambda storage, loc: storage).to(device)\n",
    "if isinstance(model, nn.DataParallel):\n",
    "    model = model.module\n",
    "    \n",
    "model.device = device\n",
    "y_hats = model.recognize(feature.unsqueeze(0), input_length)\n",
    "sentence = vocab.label_to_string(y_hats.cpu().detach().numpy())\n",
    "\n",
    "plt.plot(wav_data)\n",
    "\n",
    "print('')\n",
    "print(revise(sentence))\n",
    "ipd.Audio(wav_data, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
